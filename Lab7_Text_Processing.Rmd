---
title: "Laboratorio 7: Text Processing"
author: "Christian Barrios"
date: "`r Sys.Date()`"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Cargar librerías necesarias
```{r}
library(dplyr)
library(tm)
library(wordcloud)
library(ggplot2)
```

## Cargar los datasets
```{r}
metadata <- read.csv('Health_and_Personal_Care_metadata.csv', stringsAsFactors = FALSE)
reviews <- read.csv('Health_and_Personal_Care.csv', stringsAsFactors = FALSE)
```

## Pregunta 1: Cuántos productos contienen reviews con las palabras “love”, “recommend” y “enjoy”?
```{r}
keywords <- c('love', 'recommend', 'enjoy')
filtered_reviews <- reviews %>%
  filter(grepl(paste(keywords, collapse = '|'), text, ignore.case = TRUE))

# Obtener la cantidad de productos 
unique_products <- length(unique(filtered_reviews$parent_id))

cat('Total de productos con reviews que contienen las palabras:', unique_products, '\n')

```

## Pregunta 2: Top 5 de tiendas que venden esos productos
```{r}
filtered_reviews_metadata <- filtered_reviews %>%
  inner_join(metadata, by = 'parent_id')

# Agrupar por tienda y contar el número de productos únicos
top_stores <- filtered_reviews_metadata %>%
  group_by(store) %>%
  summarise(product_count = n_distinct(parent_id)) %>%
  arrange(desc(product_count)) %>%
  head(5)

cat('Top 5 tiendas:\n')
print(top_stores)

```

## Pregunta 3: Generar un wordcloud sin stopwords de los reviews de la pregunta 1
```{r}
reviews_corpus <- Corpus(VectorSource(filtered_reviews$text))
reviews_corpus <- tm_map(reviews_corpus, content_transformer(tolower))
reviews_corpus <- tm_map(reviews_corpus, removePunctuation)
reviews_corpus <- tm_map(reviews_corpus, removeNumbers)
reviews_corpus <- tm_map(reviews_corpus, removeWords, stopwords('en'))
reviews_corpus <- tm_map(reviews_corpus, stripWhitespace)

wordcloud(reviews_corpus, max.words = 100, random.order = FALSE)

```

## Pregunta 4: Generar un wordcloud de los reviews de las 5 tiendas encontradas
```{r}
top_stores_list <- top_stores$store

# Filtrar los reviews de las tiendas en el top 5
top_stores_reviews <- filtered_reviews_metadata %>%
  filter(store %in% top_stores_list)

top_stores_reviews <- top_stores_reviews %>%
  filter(!is.na(text) & text != '')

top_stores_corpus <- Corpus(VectorSource(top_stores_reviews$text))

top_stores_corpus <- tm_map(top_stores_corpus, content_transformer(tolower))
top_stores_corpus <- tm_map(top_stores_corpus, removePunctuation)
top_stores_corpus <- tm_map(top_stores_corpus, removeNumbers)
top_stores_corpus <- tm_map(top_stores_corpus, removeWords, stopwords('en'))
top_stores_corpus <- tm_map(top_stores_corpus, stripWhitespace)

# Generar el wordcloud
wordcloud(top_stores_corpus, max.words = 100, random.order = FALSE, scale = c(2, 0.25))


```

## Pregunta 5: Cuáles son las 25 palabras más frecuentes de los reviews
```{r}
dtm <- TermDocumentMatrix(reviews_corpus)
word_freqs <- slam::row_sums(dtm)
word_freqs <- sort(word_freqs, decreasing = TRUE)
word_freqs_df <- data.frame(word = names(word_freqs), freq = word_freqs)

cat('Las 25 palabras más frecuentes:\n')
print(head(word_freqs_df, 25))

top_25_words <- head(word_freqs_df, 25)
ggplot(top_25_words, aes(x = reorder(word, freq), y = freq)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  xlab('Palabra') +
  ylab('Frecuencia') +
  ggtitle('Top 25 palabras más frecuentes en los reviews')

```
